{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 12750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0392156862745098,
      "grad_norm": 1.4353578090667725,
      "learning_rate": 1.9923137254901962e-05,
      "loss": 1.0995,
      "step": 50
    },
    {
      "epoch": 0.0784313725490196,
      "grad_norm": 5.13701868057251,
      "learning_rate": 1.9844705882352944e-05,
      "loss": 1.0823,
      "step": 100
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 1.2782655954360962,
      "learning_rate": 1.9766274509803923e-05,
      "loss": 1.0831,
      "step": 150
    },
    {
      "epoch": 0.1568627450980392,
      "grad_norm": 6.520074844360352,
      "learning_rate": 1.9687843137254902e-05,
      "loss": 0.9605,
      "step": 200
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 3.3795361518859863,
      "learning_rate": 1.9609411764705884e-05,
      "loss": 0.9718,
      "step": 250
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 14.421175003051758,
      "learning_rate": 1.9530980392156863e-05,
      "loss": 1.0015,
      "step": 300
    },
    {
      "epoch": 0.27450980392156865,
      "grad_norm": 7.587610244750977,
      "learning_rate": 1.9452549019607845e-05,
      "loss": 0.9915,
      "step": 350
    },
    {
      "epoch": 0.3137254901960784,
      "grad_norm": 6.160135269165039,
      "learning_rate": 1.9374117647058824e-05,
      "loss": 0.8424,
      "step": 400
    },
    {
      "epoch": 0.35294117647058826,
      "grad_norm": 15.679390907287598,
      "learning_rate": 1.9295686274509806e-05,
      "loss": 0.8197,
      "step": 450
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 11.902475357055664,
      "learning_rate": 1.9217254901960788e-05,
      "loss": 0.966,
      "step": 500
    },
    {
      "epoch": 0.43137254901960786,
      "grad_norm": 4.605875015258789,
      "learning_rate": 1.9138823529411764e-05,
      "loss": 0.8428,
      "step": 550
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 4.821839809417725,
      "learning_rate": 1.9060392156862746e-05,
      "loss": 0.8452,
      "step": 600
    },
    {
      "epoch": 0.5098039215686274,
      "grad_norm": 28.80971908569336,
      "learning_rate": 1.8981960784313728e-05,
      "loss": 0.8219,
      "step": 650
    },
    {
      "epoch": 0.5490196078431373,
      "grad_norm": 21.46979331970215,
      "learning_rate": 1.8903529411764707e-05,
      "loss": 0.6995,
      "step": 700
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 3.4005374908447266,
      "learning_rate": 1.882509803921569e-05,
      "loss": 0.8405,
      "step": 750
    },
    {
      "epoch": 0.6274509803921569,
      "grad_norm": 6.99915885925293,
      "learning_rate": 1.8746666666666668e-05,
      "loss": 0.9018,
      "step": 800
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 45.65720748901367,
      "learning_rate": 1.866823529411765e-05,
      "loss": 0.7599,
      "step": 850
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 10.9812650680542,
      "learning_rate": 1.858980392156863e-05,
      "loss": 0.8847,
      "step": 900
    },
    {
      "epoch": 0.7450980392156863,
      "grad_norm": 29.29352569580078,
      "learning_rate": 1.8511372549019608e-05,
      "loss": 0.9012,
      "step": 950
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 26.71435546875,
      "learning_rate": 1.843294117647059e-05,
      "loss": 0.7767,
      "step": 1000
    },
    {
      "epoch": 0.8235294117647058,
      "grad_norm": 78.5350570678711,
      "learning_rate": 1.835450980392157e-05,
      "loss": 0.6762,
      "step": 1050
    },
    {
      "epoch": 0.8627450980392157,
      "grad_norm": 27.16093635559082,
      "learning_rate": 1.827607843137255e-05,
      "loss": 0.9324,
      "step": 1100
    },
    {
      "epoch": 0.9019607843137255,
      "grad_norm": 13.654057502746582,
      "learning_rate": 1.819764705882353e-05,
      "loss": 0.7764,
      "step": 1150
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 4.91484260559082,
      "learning_rate": 1.8119215686274512e-05,
      "loss": 0.7252,
      "step": 1200
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 2.04152512550354,
      "learning_rate": 1.804078431372549e-05,
      "loss": 0.7115,
      "step": 1250
    },
    {
      "epoch": 1.0196078431372548,
      "grad_norm": 6.40461540222168,
      "learning_rate": 1.7962352941176473e-05,
      "loss": 0.6943,
      "step": 1300
    },
    {
      "epoch": 1.0588235294117647,
      "grad_norm": 3.5899465084075928,
      "learning_rate": 1.7883921568627452e-05,
      "loss": 0.6113,
      "step": 1350
    },
    {
      "epoch": 1.0980392156862746,
      "grad_norm": 33.59101867675781,
      "learning_rate": 1.780549019607843e-05,
      "loss": 0.664,
      "step": 1400
    },
    {
      "epoch": 1.1372549019607843,
      "grad_norm": 17.12133026123047,
      "learning_rate": 1.7727058823529413e-05,
      "loss": 0.6984,
      "step": 1450
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 144.14930725097656,
      "learning_rate": 1.7648627450980395e-05,
      "loss": 0.8396,
      "step": 1500
    },
    {
      "epoch": 1.215686274509804,
      "grad_norm": 72.85814666748047,
      "learning_rate": 1.7570196078431374e-05,
      "loss": 0.9194,
      "step": 1550
    },
    {
      "epoch": 1.2549019607843137,
      "grad_norm": 0.7281566858291626,
      "learning_rate": 1.7491764705882356e-05,
      "loss": 0.6358,
      "step": 1600
    },
    {
      "epoch": 1.2941176470588236,
      "grad_norm": 0.4362771809101105,
      "learning_rate": 1.7413333333333335e-05,
      "loss": 0.6953,
      "step": 1650
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.6848620176315308,
      "learning_rate": 1.7334901960784317e-05,
      "loss": 0.6991,
      "step": 1700
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 4.097776412963867,
      "learning_rate": 1.7256470588235296e-05,
      "loss": 0.8372,
      "step": 1750
    },
    {
      "epoch": 1.4117647058823528,
      "grad_norm": 39.15254592895508,
      "learning_rate": 1.7178039215686275e-05,
      "loss": 0.7227,
      "step": 1800
    },
    {
      "epoch": 1.4509803921568627,
      "grad_norm": 0.7559927701950073,
      "learning_rate": 1.7099607843137257e-05,
      "loss": 0.6166,
      "step": 1850
    },
    {
      "epoch": 1.4901960784313726,
      "grad_norm": 19.695295333862305,
      "learning_rate": 1.7021176470588236e-05,
      "loss": 0.5961,
      "step": 1900
    },
    {
      "epoch": 1.5294117647058822,
      "grad_norm": 32.206295013427734,
      "learning_rate": 1.6942745098039218e-05,
      "loss": 0.9017,
      "step": 1950
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 8.08376693725586,
      "learning_rate": 1.6864313725490197e-05,
      "loss": 0.6624,
      "step": 2000
    },
    {
      "epoch": 1.607843137254902,
      "grad_norm": 1.6449424028396606,
      "learning_rate": 1.678588235294118e-05,
      "loss": 0.6698,
      "step": 2050
    },
    {
      "epoch": 1.6470588235294117,
      "grad_norm": 67.6962890625,
      "learning_rate": 1.6707450980392158e-05,
      "loss": 0.6951,
      "step": 2100
    },
    {
      "epoch": 1.6862745098039216,
      "grad_norm": 20.28883171081543,
      "learning_rate": 1.6629019607843137e-05,
      "loss": 0.7907,
      "step": 2150
    },
    {
      "epoch": 1.7254901960784315,
      "grad_norm": 5.889624118804932,
      "learning_rate": 1.655058823529412e-05,
      "loss": 0.7279,
      "step": 2200
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 34.69980239868164,
      "learning_rate": 1.6472156862745098e-05,
      "loss": 0.8327,
      "step": 2250
    },
    {
      "epoch": 1.803921568627451,
      "grad_norm": 1.4816555976867676,
      "learning_rate": 1.639372549019608e-05,
      "loss": 0.6123,
      "step": 2300
    },
    {
      "epoch": 1.843137254901961,
      "grad_norm": 2.3644514083862305,
      "learning_rate": 1.631529411764706e-05,
      "loss": 0.6609,
      "step": 2350
    },
    {
      "epoch": 1.8823529411764706,
      "grad_norm": 33.48097610473633,
      "learning_rate": 1.623686274509804e-05,
      "loss": 0.6364,
      "step": 2400
    },
    {
      "epoch": 1.9215686274509802,
      "grad_norm": 10.710192680358887,
      "learning_rate": 1.6158431372549023e-05,
      "loss": 0.732,
      "step": 2450
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 17.09778594970703,
      "learning_rate": 1.6080000000000002e-05,
      "loss": 0.7253,
      "step": 2500
    },
    {
      "epoch": 2.0,
      "grad_norm": 4.620177268981934,
      "learning_rate": 1.600156862745098e-05,
      "loss": 0.7604,
      "step": 2550
    },
    {
      "epoch": 2.0392156862745097,
      "grad_norm": 5.665541648864746,
      "learning_rate": 1.5923137254901963e-05,
      "loss": 0.5437,
      "step": 2600
    },
    {
      "epoch": 2.0784313725490198,
      "grad_norm": 0.22122062742710114,
      "learning_rate": 1.5844705882352942e-05,
      "loss": 0.3642,
      "step": 2650
    },
    {
      "epoch": 2.1176470588235294,
      "grad_norm": 4.68231725692749,
      "learning_rate": 1.5766274509803924e-05,
      "loss": 0.535,
      "step": 2700
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 0.24463318288326263,
      "learning_rate": 1.5687843137254903e-05,
      "loss": 0.4153,
      "step": 2750
    },
    {
      "epoch": 2.196078431372549,
      "grad_norm": 153.72520446777344,
      "learning_rate": 1.5609411764705885e-05,
      "loss": 0.5842,
      "step": 2800
    },
    {
      "epoch": 2.235294117647059,
      "grad_norm": 0.21186567842960358,
      "learning_rate": 1.5530980392156864e-05,
      "loss": 0.4679,
      "step": 2850
    },
    {
      "epoch": 2.2745098039215685,
      "grad_norm": 57.0851936340332,
      "learning_rate": 1.5452549019607846e-05,
      "loss": 0.5579,
      "step": 2900
    },
    {
      "epoch": 2.313725490196078,
      "grad_norm": 0.1193329244852066,
      "learning_rate": 1.5374117647058825e-05,
      "loss": 0.4935,
      "step": 2950
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 24.8421630859375,
      "learning_rate": 1.5295686274509804e-05,
      "loss": 0.572,
      "step": 3000
    },
    {
      "epoch": 2.392156862745098,
      "grad_norm": 1.4495420455932617,
      "learning_rate": 1.5217254901960786e-05,
      "loss": 0.4394,
      "step": 3050
    },
    {
      "epoch": 2.431372549019608,
      "grad_norm": 91.66474914550781,
      "learning_rate": 1.5138823529411766e-05,
      "loss": 0.4592,
      "step": 3100
    },
    {
      "epoch": 2.4705882352941178,
      "grad_norm": 0.147556334733963,
      "learning_rate": 1.5060392156862747e-05,
      "loss": 0.6754,
      "step": 3150
    },
    {
      "epoch": 2.5098039215686274,
      "grad_norm": 4.502880096435547,
      "learning_rate": 1.4981960784313727e-05,
      "loss": 0.6053,
      "step": 3200
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 16.89535903930664,
      "learning_rate": 1.4903529411764708e-05,
      "loss": 0.6795,
      "step": 3250
    },
    {
      "epoch": 2.588235294117647,
      "grad_norm": 1.185341238975525,
      "learning_rate": 1.4825098039215688e-05,
      "loss": 0.4652,
      "step": 3300
    },
    {
      "epoch": 2.627450980392157,
      "grad_norm": 4.725030422210693,
      "learning_rate": 1.4746666666666667e-05,
      "loss": 0.5447,
      "step": 3350
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 8.44756031036377,
      "learning_rate": 1.4668235294117648e-05,
      "loss": 0.6234,
      "step": 3400
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 0.15739481151103973,
      "learning_rate": 1.4589803921568628e-05,
      "loss": 0.4627,
      "step": 3450
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 0.29417216777801514,
      "learning_rate": 1.4511372549019609e-05,
      "loss": 0.6271,
      "step": 3500
    },
    {
      "epoch": 2.784313725490196,
      "grad_norm": 0.4829009473323822,
      "learning_rate": 1.443294117647059e-05,
      "loss": 0.448,
      "step": 3550
    },
    {
      "epoch": 2.8235294117647056,
      "grad_norm": 18.901687622070312,
      "learning_rate": 1.435450980392157e-05,
      "loss": 0.4965,
      "step": 3600
    },
    {
      "epoch": 2.8627450980392157,
      "grad_norm": 5.178599834442139,
      "learning_rate": 1.427607843137255e-05,
      "loss": 0.5989,
      "step": 3650
    },
    {
      "epoch": 2.9019607843137254,
      "grad_norm": 5.568018913269043,
      "learning_rate": 1.419764705882353e-05,
      "loss": 0.3594,
      "step": 3700
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 2.124044179916382,
      "learning_rate": 1.411921568627451e-05,
      "loss": 0.4958,
      "step": 3750
    },
    {
      "epoch": 2.980392156862745,
      "grad_norm": 8.365005493164062,
      "learning_rate": 1.404078431372549e-05,
      "loss": 0.6297,
      "step": 3800
    },
    {
      "epoch": 3.019607843137255,
      "grad_norm": 13.516292572021484,
      "learning_rate": 1.396235294117647e-05,
      "loss": 0.558,
      "step": 3850
    },
    {
      "epoch": 3.0588235294117645,
      "grad_norm": 0.06824617832899094,
      "learning_rate": 1.3883921568627451e-05,
      "loss": 0.2756,
      "step": 3900
    },
    {
      "epoch": 3.0980392156862746,
      "grad_norm": 0.2537079155445099,
      "learning_rate": 1.3805490196078433e-05,
      "loss": 0.3414,
      "step": 3950
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 0.0850294753909111,
      "learning_rate": 1.3727058823529414e-05,
      "loss": 0.3836,
      "step": 4000
    },
    {
      "epoch": 3.176470588235294,
      "grad_norm": 889.2027587890625,
      "learning_rate": 1.3648627450980394e-05,
      "loss": 0.3003,
      "step": 4050
    },
    {
      "epoch": 3.215686274509804,
      "grad_norm": 0.053169067949056625,
      "learning_rate": 1.3570196078431375e-05,
      "loss": 0.3083,
      "step": 4100
    },
    {
      "epoch": 3.2549019607843137,
      "grad_norm": 0.06950534135103226,
      "learning_rate": 1.3491764705882354e-05,
      "loss": 0.4471,
      "step": 4150
    },
    {
      "epoch": 3.2941176470588234,
      "grad_norm": 1.4418699741363525,
      "learning_rate": 1.3413333333333334e-05,
      "loss": 0.3444,
      "step": 4200
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.10480303317308426,
      "learning_rate": 1.3334901960784315e-05,
      "loss": 0.4594,
      "step": 4250
    },
    {
      "epoch": 3.372549019607843,
      "grad_norm": 8.084187507629395,
      "learning_rate": 1.3256470588235295e-05,
      "loss": 0.3985,
      "step": 4300
    },
    {
      "epoch": 3.411764705882353,
      "grad_norm": 63.886653900146484,
      "learning_rate": 1.3178039215686276e-05,
      "loss": 0.4746,
      "step": 4350
    },
    {
      "epoch": 3.450980392156863,
      "grad_norm": 3.4125611782073975,
      "learning_rate": 1.3099607843137256e-05,
      "loss": 0.5174,
      "step": 4400
    },
    {
      "epoch": 3.4901960784313726,
      "grad_norm": 0.1634242683649063,
      "learning_rate": 1.3021176470588237e-05,
      "loss": 0.3423,
      "step": 4450
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 77.27519989013672,
      "learning_rate": 1.2942745098039217e-05,
      "loss": 0.3447,
      "step": 4500
    },
    {
      "epoch": 3.568627450980392,
      "grad_norm": 0.056283410638570786,
      "learning_rate": 1.2864313725490196e-05,
      "loss": 0.3622,
      "step": 4550
    },
    {
      "epoch": 3.607843137254902,
      "grad_norm": 0.050304923206567764,
      "learning_rate": 1.2785882352941177e-05,
      "loss": 0.3088,
      "step": 4600
    },
    {
      "epoch": 3.6470588235294117,
      "grad_norm": 0.2473730742931366,
      "learning_rate": 1.2707450980392157e-05,
      "loss": 0.492,
      "step": 4650
    },
    {
      "epoch": 3.686274509803922,
      "grad_norm": 0.062114082276821136,
      "learning_rate": 1.2629019607843138e-05,
      "loss": 0.2137,
      "step": 4700
    },
    {
      "epoch": 3.7254901960784315,
      "grad_norm": 0.0719974935054779,
      "learning_rate": 1.2550588235294118e-05,
      "loss": 0.2485,
      "step": 4750
    },
    {
      "epoch": 3.764705882352941,
      "grad_norm": 46.01002883911133,
      "learning_rate": 1.2472156862745099e-05,
      "loss": 0.3233,
      "step": 4800
    },
    {
      "epoch": 3.803921568627451,
      "grad_norm": 0.11386759579181671,
      "learning_rate": 1.2393725490196081e-05,
      "loss": 0.5534,
      "step": 4850
    },
    {
      "epoch": 3.843137254901961,
      "grad_norm": 8.388203620910645,
      "learning_rate": 1.2315294117647061e-05,
      "loss": 0.2288,
      "step": 4900
    },
    {
      "epoch": 3.8823529411764706,
      "grad_norm": 10.941542625427246,
      "learning_rate": 1.2236862745098039e-05,
      "loss": 0.4673,
      "step": 4950
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 7.503292560577393,
      "learning_rate": 1.215843137254902e-05,
      "loss": 0.3095,
      "step": 5000
    },
    {
      "epoch": 3.9607843137254903,
      "grad_norm": 0.10665592551231384,
      "learning_rate": 1.2080000000000001e-05,
      "loss": 0.441,
      "step": 5050
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.2484779804944992,
      "learning_rate": 1.2001568627450982e-05,
      "loss": 0.3628,
      "step": 5100
    },
    {
      "epoch": 4.03921568627451,
      "grad_norm": 1.2733204364776611,
      "learning_rate": 1.1923137254901962e-05,
      "loss": 0.1019,
      "step": 5150
    },
    {
      "epoch": 4.078431372549019,
      "grad_norm": 0.06695106625556946,
      "learning_rate": 1.1844705882352943e-05,
      "loss": 0.2239,
      "step": 5200
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 321.764892578125,
      "learning_rate": 1.1766274509803923e-05,
      "loss": 0.1969,
      "step": 5250
    },
    {
      "epoch": 4.1568627450980395,
      "grad_norm": 0.03905345872044563,
      "learning_rate": 1.1687843137254904e-05,
      "loss": 0.1901,
      "step": 5300
    },
    {
      "epoch": 4.196078431372549,
      "grad_norm": 1.0080904960632324,
      "learning_rate": 1.1609411764705883e-05,
      "loss": 0.3151,
      "step": 5350
    },
    {
      "epoch": 4.235294117647059,
      "grad_norm": 0.924108624458313,
      "learning_rate": 1.1530980392156863e-05,
      "loss": 0.2407,
      "step": 5400
    },
    {
      "epoch": 4.2745098039215685,
      "grad_norm": 0.07608345150947571,
      "learning_rate": 1.1452549019607844e-05,
      "loss": 0.3235,
      "step": 5450
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 0.0385451465845108,
      "learning_rate": 1.1374117647058824e-05,
      "loss": 0.2015,
      "step": 5500
    },
    {
      "epoch": 4.352941176470588,
      "grad_norm": 2.89404559135437,
      "learning_rate": 1.1295686274509805e-05,
      "loss": 0.2618,
      "step": 5550
    },
    {
      "epoch": 4.392156862745098,
      "grad_norm": 1.7904196977615356,
      "learning_rate": 1.1217254901960785e-05,
      "loss": 0.2554,
      "step": 5600
    },
    {
      "epoch": 4.431372549019608,
      "grad_norm": 0.014626143500208855,
      "learning_rate": 1.1138823529411766e-05,
      "loss": 0.1427,
      "step": 5650
    },
    {
      "epoch": 4.470588235294118,
      "grad_norm": 0.02048376575112343,
      "learning_rate": 1.1060392156862746e-05,
      "loss": 0.1639,
      "step": 5700
    },
    {
      "epoch": 4.509803921568627,
      "grad_norm": 0.05341707915067673,
      "learning_rate": 1.0981960784313725e-05,
      "loss": 0.4367,
      "step": 5750
    },
    {
      "epoch": 4.549019607843137,
      "grad_norm": 0.048875126987695694,
      "learning_rate": 1.0903529411764706e-05,
      "loss": 0.1907,
      "step": 5800
    },
    {
      "epoch": 4.588235294117647,
      "grad_norm": 112.84764099121094,
      "learning_rate": 1.0825098039215686e-05,
      "loss": 0.2728,
      "step": 5850
    },
    {
      "epoch": 4.627450980392156,
      "grad_norm": 0.10771019011735916,
      "learning_rate": 1.0746666666666668e-05,
      "loss": 0.2518,
      "step": 5900
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 0.11226353794336319,
      "learning_rate": 1.0668235294117649e-05,
      "loss": 0.2806,
      "step": 5950
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 0.029532410204410553,
      "learning_rate": 1.058980392156863e-05,
      "loss": 0.1082,
      "step": 6000
    },
    {
      "epoch": 4.745098039215686,
      "grad_norm": 0.02212774194777012,
      "learning_rate": 1.051137254901961e-05,
      "loss": 0.1945,
      "step": 6050
    },
    {
      "epoch": 4.784313725490196,
      "grad_norm": 0.05323217064142227,
      "learning_rate": 1.043294117647059e-05,
      "loss": 0.1287,
      "step": 6100
    },
    {
      "epoch": 4.823529411764706,
      "grad_norm": 0.0267779603600502,
      "learning_rate": 1.0354509803921569e-05,
      "loss": 0.257,
      "step": 6150
    },
    {
      "epoch": 4.862745098039216,
      "grad_norm": 0.022346779704093933,
      "learning_rate": 1.027607843137255e-05,
      "loss": 0.3393,
      "step": 6200
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 83.65410614013672,
      "learning_rate": 1.019764705882353e-05,
      "loss": 0.2875,
      "step": 6250
    },
    {
      "epoch": 4.9411764705882355,
      "grad_norm": 6.420534610748291,
      "learning_rate": 1.011921568627451e-05,
      "loss": 0.3123,
      "step": 6300
    },
    {
      "epoch": 4.980392156862745,
      "grad_norm": 0.9688366055488586,
      "learning_rate": 1.0040784313725491e-05,
      "loss": 0.0637,
      "step": 6350
    },
    {
      "epoch": 5.019607843137255,
      "grad_norm": 0.022151077166199684,
      "learning_rate": 9.962352941176472e-06,
      "loss": 0.1781,
      "step": 6400
    },
    {
      "epoch": 5.0588235294117645,
      "grad_norm": 0.12818871438503265,
      "learning_rate": 9.883921568627452e-06,
      "loss": 0.1583,
      "step": 6450
    },
    {
      "epoch": 5.098039215686274,
      "grad_norm": 601.295166015625,
      "learning_rate": 9.805490196078433e-06,
      "loss": 0.1421,
      "step": 6500
    },
    {
      "epoch": 5.137254901960785,
      "grad_norm": 0.03687584772706032,
      "learning_rate": 9.727058823529413e-06,
      "loss": 0.063,
      "step": 6550
    },
    {
      "epoch": 5.176470588235294,
      "grad_norm": 0.03910977765917778,
      "learning_rate": 9.648627450980394e-06,
      "loss": 0.0786,
      "step": 6600
    },
    {
      "epoch": 5.215686274509804,
      "grad_norm": 0.013069156557321548,
      "learning_rate": 9.570196078431373e-06,
      "loss": 0.0874,
      "step": 6650
    },
    {
      "epoch": 5.254901960784314,
      "grad_norm": 0.010228645987808704,
      "learning_rate": 9.491764705882353e-06,
      "loss": 0.0382,
      "step": 6700
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 0.01834852434694767,
      "learning_rate": 9.413333333333334e-06,
      "loss": 0.2291,
      "step": 6750
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 0.20635990798473358,
      "learning_rate": 9.334901960784316e-06,
      "loss": 0.1145,
      "step": 6800
    },
    {
      "epoch": 5.372549019607844,
      "grad_norm": 0.03511444479227066,
      "learning_rate": 9.256470588235295e-06,
      "loss": 0.0756,
      "step": 6850
    },
    {
      "epoch": 5.411764705882353,
      "grad_norm": 6.483320236206055,
      "learning_rate": 9.178039215686275e-06,
      "loss": 0.1854,
      "step": 6900
    },
    {
      "epoch": 5.450980392156863,
      "grad_norm": 8.168926239013672,
      "learning_rate": 9.099607843137256e-06,
      "loss": 0.2736,
      "step": 6950
    },
    {
      "epoch": 5.490196078431373,
      "grad_norm": 0.018555399030447006,
      "learning_rate": 9.021176470588236e-06,
      "loss": 0.124,
      "step": 7000
    },
    {
      "epoch": 5.529411764705882,
      "grad_norm": 0.0701325312256813,
      "learning_rate": 8.942745098039217e-06,
      "loss": 0.2861,
      "step": 7050
    },
    {
      "epoch": 5.568627450980392,
      "grad_norm": 0.022614406421780586,
      "learning_rate": 8.864313725490197e-06,
      "loss": 0.1069,
      "step": 7100
    },
    {
      "epoch": 5.607843137254902,
      "grad_norm": 0.030084319412708282,
      "learning_rate": 8.785882352941178e-06,
      "loss": 0.1633,
      "step": 7150
    },
    {
      "epoch": 5.647058823529412,
      "grad_norm": 0.30469846725463867,
      "learning_rate": 8.707450980392158e-06,
      "loss": 0.1397,
      "step": 7200
    },
    {
      "epoch": 5.686274509803922,
      "grad_norm": 259.57025146484375,
      "learning_rate": 8.629019607843137e-06,
      "loss": 0.0724,
      "step": 7250
    },
    {
      "epoch": 5.7254901960784315,
      "grad_norm": 0.024277305230498314,
      "learning_rate": 8.550588235294117e-06,
      "loss": 0.1593,
      "step": 7300
    },
    {
      "epoch": 5.764705882352941,
      "grad_norm": 0.015310321003198624,
      "learning_rate": 8.4721568627451e-06,
      "loss": 0.1902,
      "step": 7350
    },
    {
      "epoch": 5.803921568627451,
      "grad_norm": 0.016987565904855728,
      "learning_rate": 8.39372549019608e-06,
      "loss": 0.1238,
      "step": 7400
    },
    {
      "epoch": 5.8431372549019605,
      "grad_norm": 0.021056577563285828,
      "learning_rate": 8.315294117647059e-06,
      "loss": 0.1316,
      "step": 7450
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.03696834668517113,
      "learning_rate": 8.23686274509804e-06,
      "loss": 0.214,
      "step": 7500
    },
    {
      "epoch": 5.921568627450981,
      "grad_norm": 0.017670931294560432,
      "learning_rate": 8.15843137254902e-06,
      "loss": 0.0562,
      "step": 7550
    },
    {
      "epoch": 5.96078431372549,
      "grad_norm": 0.02659916877746582,
      "learning_rate": 8.08e-06,
      "loss": 0.0925,
      "step": 7600
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.013598495163023472,
      "learning_rate": 8.001568627450981e-06,
      "loss": 0.2029,
      "step": 7650
    },
    {
      "epoch": 6.03921568627451,
      "grad_norm": 0.011010995134711266,
      "learning_rate": 7.923137254901962e-06,
      "loss": 0.0403,
      "step": 7700
    },
    {
      "epoch": 6.078431372549019,
      "grad_norm": 0.02006412483751774,
      "learning_rate": 7.844705882352942e-06,
      "loss": 0.1252,
      "step": 7750
    },
    {
      "epoch": 6.117647058823529,
      "grad_norm": 0.011236654594540596,
      "learning_rate": 7.766274509803923e-06,
      "loss": 0.0871,
      "step": 7800
    },
    {
      "epoch": 6.1568627450980395,
      "grad_norm": 9.894368171691895,
      "learning_rate": 7.687843137254901e-06,
      "loss": 0.1841,
      "step": 7850
    },
    {
      "epoch": 6.196078431372549,
      "grad_norm": 0.019832594320178032,
      "learning_rate": 7.609411764705883e-06,
      "loss": 0.0191,
      "step": 7900
    },
    {
      "epoch": 6.235294117647059,
      "grad_norm": 0.01238059252500534,
      "learning_rate": 7.530980392156863e-06,
      "loss": 0.073,
      "step": 7950
    },
    {
      "epoch": 6.2745098039215685,
      "grad_norm": 0.015396339818835258,
      "learning_rate": 7.452549019607845e-06,
      "loss": 0.026,
      "step": 8000
    },
    {
      "epoch": 6.313725490196078,
      "grad_norm": 0.006243936717510223,
      "learning_rate": 7.3741176470588235e-06,
      "loss": 0.1232,
      "step": 8050
    },
    {
      "epoch": 6.352941176470588,
      "grad_norm": 0.0059604342095553875,
      "learning_rate": 7.295686274509805e-06,
      "loss": 0.0377,
      "step": 8100
    },
    {
      "epoch": 6.392156862745098,
      "grad_norm": 49.97066116333008,
      "learning_rate": 7.217254901960785e-06,
      "loss": 0.0939,
      "step": 8150
    },
    {
      "epoch": 6.431372549019608,
      "grad_norm": 0.011575168929994106,
      "learning_rate": 7.138823529411766e-06,
      "loss": 0.1261,
      "step": 8200
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 0.00784314889460802,
      "learning_rate": 7.0603921568627455e-06,
      "loss": 0.0908,
      "step": 8250
    },
    {
      "epoch": 6.509803921568627,
      "grad_norm": 0.012024304829537868,
      "learning_rate": 6.981960784313726e-06,
      "loss": 0.0408,
      "step": 8300
    },
    {
      "epoch": 6.549019607843137,
      "grad_norm": 0.007749218959361315,
      "learning_rate": 6.9035294117647066e-06,
      "loss": 0.0392,
      "step": 8350
    },
    {
      "epoch": 6.588235294117647,
      "grad_norm": 0.01852402463555336,
      "learning_rate": 6.825098039215687e-06,
      "loss": 0.0305,
      "step": 8400
    },
    {
      "epoch": 6.627450980392156,
      "grad_norm": 6.106621265411377,
      "learning_rate": 6.746666666666667e-06,
      "loss": 0.1581,
      "step": 8450
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.008916904218494892,
      "learning_rate": 6.668235294117647e-06,
      "loss": 0.0813,
      "step": 8500
    },
    {
      "epoch": 6.705882352941177,
      "grad_norm": 0.010304635390639305,
      "learning_rate": 6.589803921568629e-06,
      "loss": 0.1605,
      "step": 8550
    },
    {
      "epoch": 6.745098039215686,
      "grad_norm": 0.011332361027598381,
      "learning_rate": 6.511372549019609e-06,
      "loss": 0.0031,
      "step": 8600
    },
    {
      "epoch": 6.784313725490196,
      "grad_norm": 0.016386212781071663,
      "learning_rate": 6.432941176470589e-06,
      "loss": 0.1111,
      "step": 8650
    },
    {
      "epoch": 6.823529411764706,
      "grad_norm": 0.014281858690083027,
      "learning_rate": 6.354509803921569e-06,
      "loss": 0.0377,
      "step": 8700
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 0.044063959270715714,
      "learning_rate": 6.27607843137255e-06,
      "loss": 0.0987,
      "step": 8750
    },
    {
      "epoch": 6.901960784313726,
      "grad_norm": 0.006257463712245226,
      "learning_rate": 6.19764705882353e-06,
      "loss": 0.0821,
      "step": 8800
    },
    {
      "epoch": 6.9411764705882355,
      "grad_norm": 0.028160488232970238,
      "learning_rate": 6.11921568627451e-06,
      "loss": 0.1711,
      "step": 8850
    },
    {
      "epoch": 6.980392156862745,
      "grad_norm": 0.012788843363523483,
      "learning_rate": 6.0407843137254905e-06,
      "loss": 0.0768,
      "step": 8900
    },
    {
      "epoch": 7.019607843137255,
      "grad_norm": 0.012358088977634907,
      "learning_rate": 5.962352941176471e-06,
      "loss": 0.1138,
      "step": 8950
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 0.00959762092679739,
      "learning_rate": 5.883921568627452e-06,
      "loss": 0.0459,
      "step": 9000
    },
    {
      "epoch": 7.098039215686274,
      "grad_norm": 0.008793014101684093,
      "learning_rate": 5.805490196078431e-06,
      "loss": 0.0523,
      "step": 9050
    },
    {
      "epoch": 7.137254901960785,
      "grad_norm": 0.0077904644422233105,
      "learning_rate": 5.7270588235294125e-06,
      "loss": 0.037,
      "step": 9100
    },
    {
      "epoch": 7.176470588235294,
      "grad_norm": 0.005677446722984314,
      "learning_rate": 5.648627450980393e-06,
      "loss": 0.1141,
      "step": 9150
    },
    {
      "epoch": 7.215686274509804,
      "grad_norm": 0.00581477303057909,
      "learning_rate": 5.5701960784313736e-06,
      "loss": 0.0004,
      "step": 9200
    },
    {
      "epoch": 7.254901960784314,
      "grad_norm": 0.005013658665120602,
      "learning_rate": 5.491764705882353e-06,
      "loss": 0.0004,
      "step": 9250
    },
    {
      "epoch": 7.294117647058823,
      "grad_norm": 0.02302917093038559,
      "learning_rate": 5.413333333333334e-06,
      "loss": 0.0375,
      "step": 9300
    },
    {
      "epoch": 7.333333333333333,
      "grad_norm": 0.0036630132235586643,
      "learning_rate": 5.334901960784314e-06,
      "loss": 0.1046,
      "step": 9350
    },
    {
      "epoch": 7.372549019607844,
      "grad_norm": 0.005022945813834667,
      "learning_rate": 5.256470588235295e-06,
      "loss": 0.0044,
      "step": 9400
    },
    {
      "epoch": 7.411764705882353,
      "grad_norm": 0.002882704371586442,
      "learning_rate": 5.1780392156862744e-06,
      "loss": 0.0326,
      "step": 9450
    },
    {
      "epoch": 7.450980392156863,
      "grad_norm": 0.004405943676829338,
      "learning_rate": 5.099607843137255e-06,
      "loss": 0.1123,
      "step": 9500
    },
    {
      "epoch": 7.490196078431373,
      "grad_norm": 0.017050424590706825,
      "learning_rate": 5.021176470588236e-06,
      "loss": 0.0065,
      "step": 9550
    },
    {
      "epoch": 7.529411764705882,
      "grad_norm": 0.004575944505631924,
      "learning_rate": 4.942745098039216e-06,
      "loss": 0.0418,
      "step": 9600
    },
    {
      "epoch": 7.568627450980392,
      "grad_norm": 0.003249557688832283,
      "learning_rate": 4.8643137254901965e-06,
      "loss": 0.0422,
      "step": 9650
    },
    {
      "epoch": 7.607843137254902,
      "grad_norm": 0.022083714604377747,
      "learning_rate": 4.785882352941177e-06,
      "loss": 0.0891,
      "step": 9700
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 0.003838692093268037,
      "learning_rate": 4.707450980392157e-06,
      "loss": 0.0003,
      "step": 9750
    },
    {
      "epoch": 7.686274509803922,
      "grad_norm": 0.003784250235185027,
      "learning_rate": 4.629019607843138e-06,
      "loss": 0.0445,
      "step": 9800
    },
    {
      "epoch": 7.7254901960784315,
      "grad_norm": 0.006897139362990856,
      "learning_rate": 4.550588235294118e-06,
      "loss": 0.0948,
      "step": 9850
    },
    {
      "epoch": 7.764705882352941,
      "grad_norm": 0.01595458760857582,
      "learning_rate": 4.472156862745098e-06,
      "loss": 0.0361,
      "step": 9900
    },
    {
      "epoch": 7.803921568627451,
      "grad_norm": 0.004533275030553341,
      "learning_rate": 4.393725490196079e-06,
      "loss": 0.0005,
      "step": 9950
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 0.004560368601232767,
      "learning_rate": 4.315294117647059e-06,
      "loss": 0.0238,
      "step": 10000
    },
    {
      "epoch": 7.882352941176471,
      "grad_norm": 0.003918500617146492,
      "learning_rate": 4.236862745098039e-06,
      "loss": 0.0007,
      "step": 10050
    },
    {
      "epoch": 7.921568627450981,
      "grad_norm": 0.0027539976872503757,
      "learning_rate": 4.15843137254902e-06,
      "loss": 0.0398,
      "step": 10100
    },
    {
      "epoch": 7.96078431372549,
      "grad_norm": 0.003536844626069069,
      "learning_rate": 4.08e-06,
      "loss": 0.0583,
      "step": 10150
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.00784663949161768,
      "learning_rate": 4.00156862745098e-06,
      "loss": 0.0641,
      "step": 10200
    },
    {
      "epoch": 8.03921568627451,
      "grad_norm": 0.003930396866053343,
      "learning_rate": 3.923137254901961e-06,
      "loss": 0.0035,
      "step": 10250
    },
    {
      "epoch": 8.07843137254902,
      "grad_norm": 0.002503229072317481,
      "learning_rate": 3.8447058823529414e-06,
      "loss": 0.0516,
      "step": 10300
    },
    {
      "epoch": 8.117647058823529,
      "grad_norm": 0.0025664540007710457,
      "learning_rate": 3.7662745098039215e-06,
      "loss": 0.0202,
      "step": 10350
    },
    {
      "epoch": 8.156862745098039,
      "grad_norm": 0.005111671518534422,
      "learning_rate": 3.6878431372549025e-06,
      "loss": 0.0015,
      "step": 10400
    },
    {
      "epoch": 8.196078431372548,
      "grad_norm": 0.0027483610901981592,
      "learning_rate": 3.6094117647058825e-06,
      "loss": 0.0292,
      "step": 10450
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 0.0028970229905098677,
      "learning_rate": 3.530980392156863e-06,
      "loss": 0.0289,
      "step": 10500
    },
    {
      "epoch": 8.27450980392157,
      "grad_norm": 0.006993260700255632,
      "learning_rate": 3.452549019607843e-06,
      "loss": 0.0935,
      "step": 10550
    },
    {
      "epoch": 8.313725490196079,
      "grad_norm": 0.0031374802347272635,
      "learning_rate": 3.3741176470588237e-06,
      "loss": 0.0002,
      "step": 10600
    },
    {
      "epoch": 8.352941176470589,
      "grad_norm": 0.0026373928412795067,
      "learning_rate": 3.2956862745098037e-06,
      "loss": 0.0526,
      "step": 10650
    },
    {
      "epoch": 8.392156862745098,
      "grad_norm": 0.002461701398715377,
      "learning_rate": 3.2172549019607847e-06,
      "loss": 0.0368,
      "step": 10700
    },
    {
      "epoch": 8.431372549019608,
      "grad_norm": 0.0029862208757549524,
      "learning_rate": 3.1388235294117648e-06,
      "loss": 0.0363,
      "step": 10750
    },
    {
      "epoch": 8.470588235294118,
      "grad_norm": 0.003047608770430088,
      "learning_rate": 3.0603921568627453e-06,
      "loss": 0.0009,
      "step": 10800
    },
    {
      "epoch": 8.509803921568627,
      "grad_norm": 0.0024523085448890924,
      "learning_rate": 2.9819607843137254e-06,
      "loss": 0.0005,
      "step": 10850
    },
    {
      "epoch": 8.549019607843137,
      "grad_norm": 0.0018144820351153612,
      "learning_rate": 2.9035294117647063e-06,
      "loss": 0.0001,
      "step": 10900
    },
    {
      "epoch": 8.588235294117647,
      "grad_norm": 0.004547643009573221,
      "learning_rate": 2.8250980392156864e-06,
      "loss": 0.0903,
      "step": 10950
    },
    {
      "epoch": 8.627450980392156,
      "grad_norm": 0.0025774671230465174,
      "learning_rate": 2.746666666666667e-06,
      "loss": 0.0104,
      "step": 11000
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 0.002648507710546255,
      "learning_rate": 2.668235294117647e-06,
      "loss": 0.047,
      "step": 11050
    },
    {
      "epoch": 8.705882352941176,
      "grad_norm": 0.005931340157985687,
      "learning_rate": 2.5898039215686275e-06,
      "loss": 0.0002,
      "step": 11100
    },
    {
      "epoch": 8.745098039215687,
      "grad_norm": 0.0036133211106061935,
      "learning_rate": 2.5113725490196076e-06,
      "loss": 0.0001,
      "step": 11150
    },
    {
      "epoch": 8.784313725490197,
      "grad_norm": 0.0013668873580172658,
      "learning_rate": 2.4329411764705885e-06,
      "loss": 0.0055,
      "step": 11200
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 0.0020372404251247644,
      "learning_rate": 2.354509803921569e-06,
      "loss": 0.0436,
      "step": 11250
    },
    {
      "epoch": 8.862745098039216,
      "grad_norm": 0.0019379878649488091,
      "learning_rate": 2.276078431372549e-06,
      "loss": 0.0003,
      "step": 11300
    },
    {
      "epoch": 8.901960784313726,
      "grad_norm": 6.473207473754883,
      "learning_rate": 2.1976470588235296e-06,
      "loss": 0.0827,
      "step": 11350
    },
    {
      "epoch": 8.941176470588236,
      "grad_norm": 0.008892038837075233,
      "learning_rate": 2.11921568627451e-06,
      "loss": 0.0002,
      "step": 11400
    },
    {
      "epoch": 8.980392156862745,
      "grad_norm": 0.009849266149103642,
      "learning_rate": 2.0407843137254902e-06,
      "loss": 0.0884,
      "step": 11450
    },
    {
      "epoch": 9.019607843137255,
      "grad_norm": 0.002558652311563492,
      "learning_rate": 1.9623529411764708e-06,
      "loss": 0.0002,
      "step": 11500
    },
    {
      "epoch": 9.058823529411764,
      "grad_norm": 0.002261485904455185,
      "learning_rate": 1.8839215686274513e-06,
      "loss": 0.0002,
      "step": 11550
    },
    {
      "epoch": 9.098039215686274,
      "grad_norm": 0.003310293424874544,
      "learning_rate": 1.8054901960784316e-06,
      "loss": 0.0002,
      "step": 11600
    },
    {
      "epoch": 9.137254901960784,
      "grad_norm": 0.002262315945699811,
      "learning_rate": 1.7270588235294119e-06,
      "loss": 0.0002,
      "step": 11650
    },
    {
      "epoch": 9.176470588235293,
      "grad_norm": 0.001592422602698207,
      "learning_rate": 1.6486274509803924e-06,
      "loss": 0.0001,
      "step": 11700
    },
    {
      "epoch": 9.215686274509803,
      "grad_norm": 0.0017748307436704636,
      "learning_rate": 1.5701960784313727e-06,
      "loss": 0.0001,
      "step": 11750
    },
    {
      "epoch": 9.254901960784313,
      "grad_norm": 0.0016397138824686408,
      "learning_rate": 1.4917647058823532e-06,
      "loss": 0.051,
      "step": 11800
    },
    {
      "epoch": 9.294117647058824,
      "grad_norm": 0.0023653607349842787,
      "learning_rate": 1.4133333333333335e-06,
      "loss": 0.0001,
      "step": 11850
    },
    {
      "epoch": 9.333333333333334,
      "grad_norm": 0.001684760209172964,
      "learning_rate": 1.3349019607843138e-06,
      "loss": 0.0131,
      "step": 11900
    },
    {
      "epoch": 9.372549019607844,
      "grad_norm": 0.0023799987975507975,
      "learning_rate": 1.2564705882352943e-06,
      "loss": 0.0001,
      "step": 11950
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 0.0025266078300774097,
      "learning_rate": 1.1780392156862746e-06,
      "loss": 0.0361,
      "step": 12000
    },
    {
      "epoch": 9.450980392156863,
      "grad_norm": 0.002737896516919136,
      "learning_rate": 1.0996078431372551e-06,
      "loss": 0.078,
      "step": 12050
    },
    {
      "epoch": 9.490196078431373,
      "grad_norm": 0.0027568235527724028,
      "learning_rate": 1.0211764705882354e-06,
      "loss": 0.0001,
      "step": 12100
    },
    {
      "epoch": 9.529411764705882,
      "grad_norm": 0.001980334986001253,
      "learning_rate": 9.427450980392158e-07,
      "loss": 0.0001,
      "step": 12150
    },
    {
      "epoch": 9.568627450980392,
      "grad_norm": 0.002202792791649699,
      "learning_rate": 8.643137254901962e-07,
      "loss": 0.0001,
      "step": 12200
    },
    {
      "epoch": 9.607843137254902,
      "grad_norm": 0.0014750848058611155,
      "learning_rate": 7.858823529411766e-07,
      "loss": 0.0002,
      "step": 12250
    },
    {
      "epoch": 9.647058823529411,
      "grad_norm": 0.0059365988709032536,
      "learning_rate": 7.074509803921569e-07,
      "loss": 0.0201,
      "step": 12300
    },
    {
      "epoch": 9.686274509803921,
      "grad_norm": 0.0028421792667359114,
      "learning_rate": 6.290196078431373e-07,
      "loss": 0.0001,
      "step": 12350
    },
    {
      "epoch": 9.72549019607843,
      "grad_norm": 0.001816295669414103,
      "learning_rate": 5.505882352941176e-07,
      "loss": 0.0004,
      "step": 12400
    },
    {
      "epoch": 9.764705882352942,
      "grad_norm": 0.009282790124416351,
      "learning_rate": 4.7215686274509805e-07,
      "loss": 0.0434,
      "step": 12450
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 0.002006475580856204,
      "learning_rate": 3.9372549019607846e-07,
      "loss": 0.0003,
      "step": 12500
    },
    {
      "epoch": 9.843137254901961,
      "grad_norm": 0.0022652337793260813,
      "learning_rate": 3.1529411764705886e-07,
      "loss": 0.0461,
      "step": 12550
    },
    {
      "epoch": 9.882352941176471,
      "grad_norm": 0.0026954282075166702,
      "learning_rate": 2.3686274509803924e-07,
      "loss": 0.0149,
      "step": 12600
    },
    {
      "epoch": 9.92156862745098,
      "grad_norm": 0.0017797413747757673,
      "learning_rate": 1.5843137254901962e-07,
      "loss": 0.0002,
      "step": 12650
    },
    {
      "epoch": 9.96078431372549,
      "grad_norm": 0.0071539427153766155,
      "learning_rate": 8e-08,
      "loss": 0.003,
      "step": 12700
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.003185239853337407,
      "learning_rate": 1.5686274509803923e-09,
      "loss": 0.1271,
      "step": 12750
    }
  ],
  "logging_steps": 50,
  "max_steps": 12750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.3764330059264e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
